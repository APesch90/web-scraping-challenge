{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a08ead2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser\n",
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e14baf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Browser \n",
    "\n",
    "def init_browser():\n",
    "    executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "    return Browser(\"chrome\", **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3383c9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape News Headline\n",
    "def scrape_news():\n",
    "    browser = init_browser()\n",
    "    url = 'https://redplanetscience.com/'\n",
    "    browser.visit(url)\n",
    "    time.sleep(2)\n",
    "    html = browser.html\n",
    "    soup = bs(html, 'html.parser')\n",
    "    news_title = soup.find('div', class_='content_title').text\n",
    "    news_p = soup.find('div', class_='article_teaser_body').text\n",
    "    browser.quit()\n",
    "    return [news_title, news_p]\n",
    "\n",
    "#print(scrape_news())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0ca4542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape Featured Image\n",
    "\n",
    "def scrape_image():\n",
    "    browser = init_browser()\n",
    "    url = 'https://spaceimages-mars.com'\n",
    "    browser.visit(url)\n",
    "    time.sleep(2)\n",
    "    html = browser.html\n",
    "    soup = bs(html, 'html.parser')\n",
    "    relative_image_path = soup.find_all('img')[1]['src']\n",
    "    featured_image_url = url + \"/\" + relative_image_path\n",
    "    browser.quit()\n",
    "    return(featured_image_url)\n",
    "\n",
    "#print(scrape_image())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8be13eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape Mars Facts Table\n",
    "\n",
    "\"\"\"Visit the Mars Facts webpage [here](https://galaxyfacts-mars.com) \n",
    "and use Pandas to scrape the table containing facts about the planet \n",
    "including Diameter, Mass, etc.\"\"\"\n",
    "\n",
    "# Use Pandas to convert the data to a HTML table string.\n",
    "def scrape_facts():\n",
    "    url = 'https://galaxyfacts-mars.com'\n",
    "    table_pandas = pd.read_html(url)[0]\n",
    "    table_pandas = table_pandas.iloc[1:]\n",
    "    table_pandas.columns = ['Description', 'Mars', 'Earth']\n",
    "    table_pandas = table_pandas.set_index('Description')\n",
    "\n",
    "    table_pandas = table_pandas.to_html()\n",
    "    return table_pandas\n",
    "\n",
    "#print(scrape_facts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7e80aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 91.0.4472\n",
      "Get LATEST driver version for 91.0.4472\n",
      "Get LATEST driver version for 91.0.4472\n",
      "Trying to download new driver from https://chromedriver.storage.googleapis.com/91.0.4472.101/chromedriver_mac64.zip\n",
      "Driver has been saved in cache [/Users/amandapesch/.wdm/drivers/chromedriver/mac64/91.0.4472.101]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/full.jpg\n",
      "images/schiaparelli_enhanced-full.jpg\n",
      "images/syrtis_major_enhanced-full.jpg\n",
      "images/valles_marineris_enhanced-full.jpg\n",
      "[{'title': 'Cerberus Hemisphere', 'img_url': 'https://marshemispheres.com/images/full.jpg'}, {'title': 'Schiaparelli Hemisphere', 'img_url': 'https://marshemispheres.com/images/schiaparelli_enhanced-full.jpg'}, {'title': 'Syrtis Major Hemisphere', 'img_url': 'https://marshemispheres.com/images/syrtis_major_enhanced-full.jpg'}, {'title': 'Valles Marineris Hemisphere', 'img_url': 'https://marshemispheres.com/images/valles_marineris_enhanced-full.jpg'}]\n"
     ]
    }
   ],
   "source": [
    "## Scrape Mars Hemisphere Images\n",
    "# Step 1 - Get hemisphere titles containing the hemisphere name with Beautiful Soup\n",
    "\"\"\" Step 2 - Get image url string for the full resolution \n",
    "# hemisphere images using Splinter\"\"\"\n",
    "\n",
    "def scrape_hemispheres():\n",
    "    url = 'https://marshemispheres.com/'\n",
    "    response = requests.get(url)\n",
    "    soup_1 = bs(response.text, 'html')\n",
    "    browser = init_browser()\n",
    "    list_urls = ['https://marshemispheres.com/cerberus.html', 'https://marshemispheres.com/schiaparelli.html', \n",
    "                 'https://marshemispheres.com/syrtis.html', 'https://marshemispheres.com/valles.html'] \n",
    "    \n",
    "    results = soup_1.find_all('h3')\n",
    "\n",
    "    title_list = []\n",
    "    # For loop to get all the headers (hemispheres) \n",
    "    # dropped the 5th element called \"Back\"\n",
    "    for result in results[:4]:\n",
    "        # Grab the header text\n",
    "        header = result.text\n",
    "        # Remove the word \"Enhanced\"\n",
    "        header_cleaned = header[:-9]\n",
    "        title_list.append(header_cleaned)\n",
    "\n",
    "    final_urls_list = []\n",
    "    \n",
    "    for url in list_urls:\n",
    "        browser.visit(url)\n",
    "        time.sleep(2)\n",
    "        html = browser.html\n",
    "        soup_2 = bs(html, 'html.parser')\n",
    "        links = [a['href'] for a in soup_2.find_all('a', href=True)]\n",
    "        image_url = links[3]\n",
    "        print(image_url)\n",
    "        full_url = url + \"/\" + image_url\n",
    "        clean_url = url[:28]\n",
    "        final_urls = clean_url + image_url\n",
    "        final_urls_list.append(final_urls)\n",
    "\n",
    "    hemisphere_image_urls = [\n",
    "        {\"title\": title_list[0], \"img_url\": final_urls_list[0]},\n",
    "        {\"title\": title_list[1], \"img_url\": final_urls_list[1]},\n",
    "        {\"title\": title_list[2], \"img_url\": final_urls_list[2]},\n",
    "        {\"title\": title_list[3], \"img_url\": final_urls_list[3]}\n",
    "    ]\n",
    "\n",
    "    browser.quit()\n",
    "    return(hemisphere_image_urls)\n",
    "\n",
    "print(scrape_hemispheres())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78921777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring everything together into one dictionary\n",
    "\n",
    "mars_data = {}\n",
    "\n",
    "def scrape():\n",
    "    news = scrape_news()\n",
    "    featured_image = scrape_image()\n",
    "    facts = scrape_facts()\n",
    "    hemispheres = scrape_hemispheres()\n",
    "    \n",
    "    \n",
    "    \n",
    "    mars_data['news'] = news\n",
    "    mars_data['featured_image'] = featured_image\n",
    "    mars_data['facts'] = facts\n",
    "    mars_data['hemispheres'] = hemispheres\n",
    "    \n",
    "    return mars_data\n",
    "#print(scrape())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
